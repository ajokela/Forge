#!/usr/bin/env python

from optparse import OptionParser
from time import localtime, strftime
from string import *
import ConfigParser
import os, sys, shutil
import stat
import math
import fileinput

FORGE_HOME = os.getenv("FORGE_HOME")
FORGE_GENERATED = "build" # TODO

def err(s):
    exit("error: " + s)

def warn(s):
    print("warn: " + s)

def main():
    usage = "usage: %prog <dsl name> [options]"
    parser = OptionParser(usage)
    parser.add_option("-d", "--dest", action="store", dest="build_dir", default=os.getenv("PWD")+"/published/", help="directory to publish generated DSL")
    parser.add_option("-c", "--clean", action="store_true", dest="build_clean", default=False, help="nuke the build directory if it already exists")
    parser.add_option("--clean-extern", action="store_true", dest="extern_clean", default=False, help="always republish extern files")

    (opts, args) = parser.parse_args()
    if len(args) < 1:
        parser.error("a dsl name must be passed to publish as an argument")

    initialize()
    checkEnv()
    publish(args[0], opts)

def initialize():
    pass

def checkEnv():
    global FORGE_HOME

    if FORGE_HOME is None:
        #try to check if it is the current directory
        script_path = os.path.dirname(__file__)
        cand_home = os.path.split(script_path)[0]
        if os.path.isfile(cand_home + "/forge.key"):
            FORGE_HOME = cand_home
        else:
            err("The FORGE_HOME environment variable must be defined")

def printEnv():
    print("======== REQUIRED FORGE PUBLISH ENVIRONMENT VARIABLES =========")
    print("FORGE_HOME = " + FORGE_HOME)

def sbtBuildFile(dsl):
    s = Template("""
import sbt._
import Keys._

object ${dslName}Build extends Build {
  val virtualization_lms_core = "EPFL" % "lms_2.10" % "0.3-SNAPSHOT"
  val delite_framework = "stanford-ppl" % "framework_2.10" % "0.1-SNAPSHOT"
  val delite_runtime = "stanford-ppl" % "runtime_2.10" % "0.1-SNAPSHOT"
  val delite_tests = "stanford-ppl" % "delite-test_2.10" % "0.1-SNAPSHOT"

  val virtScala = "2.10.2-RC1"
  val virtBuildSettingsBase = Project.defaultSettings ++ Seq(
    organization := "stanford-ppl",
    scalaOrganization := "org.scala-lang.virtualized",
    scalaVersion := virtScala,
    publishArtifact in (Compile, packageDoc) := false,
    libraryDependencies += virtualization_lms_core,
    libraryDependencies += delite_framework,
    libraryDependencies += delite_runtime,
    libraryDependencies += delite_tests,
    // needed for scala.tools, which is apparently not included in sbt's built in version
    libraryDependencies += "org.scala-lang.virtualized" % "scala-library" % virtScala,
    libraryDependencies += "org.scala-lang.virtualized" % "scala-compiler" % virtScala,
    libraryDependencies += "org.apache.commons" % "commons-math" % "2.2",
    // used in delitec to access jars
    retrieveManaged := true,
    scalacOptions += "-Yno-generic-signatures",
    scalacOptions += "-Yvirtualize",
    initialCommands in console += "import ${dslNameLowerCase}.library._; val ${dslName} = new ${dslName}REPL { def main() = {} }; import ${dslName}._"
  )

  val virtBuildSettings = virtBuildSettingsBase ++ Seq(
    scalaSource in Compile <<= baseDirectory(_ / "src")
  )

  // build targets
  lazy val ${dslName}Shared = Project("${dslName}-shared", file("shared"), settings = virtBuildSettings)
  lazy val ${dslName}Comp = Project("${dslName}-comp", file("compiler"), settings = virtBuildSettings) dependsOn(${dslName}Shared)
  lazy val ${dslName}Lib = Project("${dslName}-lib", file("library"), settings = virtBuildSettings) dependsOn(${dslName}Shared)
  lazy val ${dslName}Ident = Project("${dslName}-ident", file("ident"), settings = virtBuildSettings) dependsOn(${dslName}Shared)
  lazy val ${dslName}Apps = Project("${dslName}-apps", file("apps"), settings = virtBuildSettings) dependsOn(${dslName}Comp, ${dslName}Lib, ${dslName}Ident)
  lazy val ${dslName}Tests = Project("${dslName}-tests", file("tests"), settings = virtBuildSettingsBase ++ Seq(
    scalaSource in Test <<= baseDirectory(_ / "src"),
    parallelExecution in Test := false,
    concurrentRestrictions in Test += Tags.limitAll(1) // don't run anything in parallel
  )) dependsOn(${dslName}Comp, ${dslName}Lib)
}
""")
    return s.substitute(dslName=dsl, dslNameLowerCase=dsl.lower())

def get_files(path):
    return [d + "/" + f for (d, n, fs) in os.walk(path) for f in fs] 

def check_conflict(base_dir, generated_dir):
    base = set(get_files(base_dir))
    gen = set(get_files(generated_dir))
    intersect = base.intersection(gen)
    if (len(intersect) != 0):
        for f in intersect:
            err("extern file " + f + " conflicts with generated file")

def rename_all(src, mappings):
    replfiles = get_files(src)
    infiles = fileinput.FileInput(replfiles, inplace = 1)
    for line in infiles:
        for orig,repl in mappings.iteritems():
          line = line.replace(orig,repl)          
        sys.stdout.write(line)

def publish_static_extern(dsl, build_dir, scratch_dir):
    static_dir = FORGE_HOME + "/static/extern/"
    check_conflict(static_dir, build_dir)

    # copy and perform name replacement of static extern files on the fly        
    os.system("rsync -r " + static_dir + " " + scratch_dir)
    rename_all(scratch_dir, {'HUMAN_DSL_NAME': dsl, 'LOWERCASE_DSL_NAME': dsl.lower()})
    
    # we need to mirror the package layout convention defined in Forge
    all_targets = ['shared','compiler','library']
    targets = [t for t in all_targets if os.path.exists(build_dir + t + "/src/")]
    for t in targets:
        dest_root = t + "/"
        dest = dest_root + "src/" + dsl.lower() + "/" + t + "/"
        src_root = scratch_dir + "/" + t  + "/"
        src = src_root + "src/" 
        os.system("rsync -r " + src + " " + build_dir + "/" + dest)    
        os.system("rsync -q " + src_root + "*" + " " + build_dir + "/" + dest_root) 

def publish_dsl_extern(dsl, build_dir, scratch_dir, final_name):
    extern_dir = FORGE_HOME + "/extern/" + dsl + "/"  
    if not os.path.exists(extern_dir):
        return
    check_conflict(extern_dir, build_dir)

    # recursively publish dependencies
    if os.path.exists(extern_dir + ".dependencies"):
        for line in open(extern_dir + ".dependencies"):
          publish_dsl_extern(line.rstrip("\n"), build_dir, scratch_dir, final_name)

    # we need to mirror the package layout convention defined in Forge
    all_targets = ['shared','compiler','library']
    targets = [t for t in all_targets if os.path.exists(build_dir + t + "/src/")]
    tmp_dest = scratch_dir + dsl + "_extern/"            
    for t in targets:
        dest_root = t + "/"
        dest = dest_root + "src/" + final_name.lower() + "/" + t + "/"
        src_root = extern_dir + "/" + t  + "/"
        src = src_root + "src/"
               
        if dsl != final_name:
            if not os.path.exists(tmp_dest + dest):
                  os.makedirs(tmp_dest + dest)
            os.system("rsync -r " + src + " " + tmp_dest + dest)    
            os.system("rsync -q " + src_root + "*" + " " + tmp_dest + dest_root) 
        else:
            os.system("rsync -r " + src + " " + build_dir + "/" + dest)    
            os.system("rsync -q " + src_root + "*" + " " + build_dir + "/" + dest_root) 

    if dsl != final_name:
        # dependencies need to have dsl names remapped
        rename_all(tmp_dest, {dsl: final_name, dsl.lower(): final_name.lower()})
        os.system("rsync -r " + tmp_dest + " " + build_dir) 
 
def publish(dsl, opts):
    global FORGE_HOME
    global FORGE_GENERATED

    generated_root = FORGE_HOME + "/" + FORGE_GENERATED + "/" + dsl + "/"
    if not os.path.isdir(generated_root):
        err("could not find generated DSL " + dsl + ". (did you forget to run forge?)")

    build_dir = opts.build_dir + "/" + dsl + "/"

    print "== Publishing " + dsl + " to " + build_dir
    if os.path.exists(build_dir) and opts.build_clean:
        shutil.rmtree(build_dir)
    if not os.path.exists(build_dir):
        os.makedirs(build_dir)

    # source code
    os.system("rsync -r " + FORGE_GENERATED + "/" + dsl + "/" + " " + build_dir)

    # extern
    scratch_dir = FORGE_GENERATED + "/.scratch/"
    # in the common case, extern dependencies don't change - so we
    # only republish it if the scratch directory does not exist                
    if not os.path.exists(scratch_dir) or opts.extern_clean:
        if not os.path.exists(scratch_dir):
            os.makedirs(scratch_dir)
        publish_static_extern(dsl, build_dir, scratch_dir)
        publish_dsl_extern(dsl, build_dir, scratch_dir, dsl)
    
    # apps
    apps_dir = FORGE_HOME + "/apps/" + dsl + "/"
    if os.path.exists(apps_dir):
        os.system("rsync -r " + apps_dir + " " + build_dir + "/apps/")

    # tests
    tests_dir = FORGE_HOME + "/tests/" + dsl + "/"
    if os.path.exists(tests_dir):
        os.system("rsync -r " + tests_dir + " " + build_dir + "/tests/")

    # sbt project
    if not os.path.exists(build_dir + "/project/"):
        os.mkdir(build_dir + "/project/")
        buildFile = open(build_dir + "/project/Build.scala", 'w')
        buildFile.write(sbtBuildFile(dsl))
        buildFile.close()

    # executable scripts
    if not os.path.exists(build_dir + "/bin/"):
        os.mkdir(build_dir + "/bin/")
        out_delitec = build_dir+"/bin/delitec"
        shutil.copyfile(FORGE_HOME + "/static/delitec-wrapper", out_delitec)
        os.chmod(out_delitec, stat.S_IXUSR | os.stat(out_delitec)[stat.ST_MODE])

        out_delite = build_dir+"/bin/delite"
        shutil.copyfile(FORGE_HOME + "/static/delite-wrapper", out_delite)
        os.chmod(out_delite, stat.S_IXUSR | os.stat(out_delite)[stat.ST_MODE])

        shutil.copyfile(FORGE_HOME + "/static/delitecommon-wrapper.py", build_dir+"/bin/delitecommon.py")

    print "[forge]: Publishing complete. Don't forget to run 'sbt publish-local' from your DELITE_HOME for the framework and runtime modules before compiling your new DSL."

if __name__ == "__main__":
    main()
